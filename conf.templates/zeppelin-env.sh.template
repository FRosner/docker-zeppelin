#!/bin/bash

export ZEPPELIN_NOTEBOOK_DIR="notebooks"   		# Where notebook at?

#### Spark interpreter configuration ####

export SPARK_HOME=/usr/local/spark
export SPARK_SUBMIT_OPTIONS="--driver-memory $ZEPPELIN_SPARK_DRIVER_MEMORY --conf spark.ui.port=$ZEPPELIN_SPARK_UI_PORT"

# Options read in YARN client mode
# export HADOOP_CONF_DIR         		# yarn-site.xml is located in configuration directory in HADOOP_CONF_DIR.
# Pyspark (supported with Spark 1.2.1 and above)
# To configure pyspark, you need to set spark distribution's path to 'spark.home' property in Interpreter setting screen in Zeppelin GUI
# export PYSPARK_PYTHON          		# path to the python command. must be the same path on the driver(Zeppelin) and all workers.
# export PYTHONPATH
